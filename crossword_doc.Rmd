---
title: "24 Years of NYTimes Crossword Answers"
date: "September 2, 2017"
output: 
  github_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I do the New York Times crossword pretty much every day. 90% of the time, I'll tackle it before the day actually arrives (they launch at 11pm the night before, except Sunday's, which launches at 6pm on Saturday). It's the closest thing I have to an evening ritual.

Other people have already done pretty cool explorations of crossword text data. They've looked at at comparisons to the [Oxford English Dictionary](http://blog.nycdatascience.com/student-works/web-scraping/nyt-crossword-puzzle-approximately-cool-oed/) and the [Google Books](https://noahveltman.com/crossword/about.html) corpuses (corpi?) respectively. My favorite: last year, the NYTimes themselves published an interactive piece exploring [the changing meanings of clues over the years](https://www.nytimes.com/interactive/2016/02/07/opinion/what-74-years-of-times-crosswords-say-about-the-words-we-use.html?mcubz=3).

Meanwhile, my goal here (aside from indulging my inner crossword geek) is to try out a few new packages: website scraping with `rvest` and wrangling text data with `tidytext`. 

## Getting The Data

I didn't scrape NYTimes.com itself. Why? Because crosswords tend to arrive blank, and I wanted answers. Instead, I used the `rvest` package and [Selector Gadget](http://selectorgadget.com/) to gather historical puzzle data from the amazing resource that is [XWord Info](https://www.xwordinfo.com/). 

Although the NYTimes crossword has been around since far earlier than 1994, I chose to only look at puzzles from the Will Shortz era (late 1993 - present). The scraper code is available as part of this repository.

## Some Questions

### What are the most common answers?

Starting off with something easy. What words pop up most frequently?

```{r echo = FALSE, message = FALSE, warning = FALSE}
# Setup
library(tidyverse)
library(stringr)
options(stringsAsFactors = FALSE)

crossword <- read.csv("clean_crosswords.csv") %>%
  as.tbl() %>%
  distinct()

crossword %>%
  count(word, sort = TRUE) %>%
  top_n(5)

```

It's unsurprising that these are all short, vowel-heavy words. They're likely used as short fillers between the longer, more inflexible feature words. 

What about their frequency of use over time?

```{r echo = FALSE}

crossword %>%
  filter(word == "ERA" | word == "AREA" | word == "ERE" | word == "ONE" | word == "ELI") %>%
  count(year, word, sort = TRUE) %>%
  ggplot(aes(x = year, y = n)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(~word, ncol = 2)

```

Nothing really convincing yet.

### Are words getting longer? Shorter?

Calculating the average length of each word, then plotting by year:

```{r echo = FALSE}

## Average Word Length 

crossword %>%
  group_by(year) %>%
  summarise(avg = mean(nchar(word)), sort = TRUE) %>%
  ggplot(aes(x = year, y = avg)) +
  geom_point() +
  geom_smooth(method = 'lm')

```

A weak yes, but this doesn't tell us much. Monday puzzles are designed to be far easier than Saturday puzzles. What does average word length look like for each day?

```{r echo = FALSE}

crossword %>%
  filter(cwday != "NA") %>%
  mutate(cwday = factor(cwday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  group_by(year, cwday) %>%
  summarise(avg = mean(nchar(word)), sort = TRUE) %>%
  arrange(desc(avg)) %>%
  ggplot(aes(x = year, y = avg, color = cwday)) +
  geom_point(show.legend = FALSE) +
  geom_smooth(method = 'lm') +
  facet_wrap(~cwday, nrow = 1) +
  theme(legend.position = "none") +
  labs(x = NULL, y = "Average Word Length")

```

A few observations:

- The intended puzzle complexity is reflected in the average word length for each day.
- Friday and Saturday words seem to be growing longer much faster the other days'.
- Sunday words, while pitched as comparable to Wednesdays or Thursdays, are probably a little longer on average to account for the larger grid.

### What words have emerged recently?

When different words enter the lexicon, it's only a matter of time before they're referenced in popular media like the crossword. I wanted to find the words that only became popular in recent years. 

To do this, I'm leveraging the concept of _term frequency-inverse document frequency_ (td-idf). From Julia Silge's amazing resource, [Text Mining with R](http://tidytextmining.com/tfidf.html):

>The statistic **tf-idf** is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites.

If we treat each year as separate "documents", we should be able to figure out what words are most important to each year.

```{r echo = FALSE, warning = FALSE}
library(tidytext)

year_words <- crossword %>%
  count(year, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, year, n) %>%
  arrange(desc(tf_idf))

year_words

```

Some curious results already, but we'll have to dig deeper to get anything particularly interesting. 

Plotting the words most important to the last 5 years:

```{r echo = FALSE}
plot_year_words <- year_words %>%
  mutate(word = factor(word, levels = rev(unique(word))))

plot_year_words %>%
  filter(year >= 2013) %>%
  group_by(year) %>%
  top_n(5) %>%
  ungroup %>%
  ggplot(aes(x = word, y = tf_idf, fill = year)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year, ncol = 2, scales = "free") +
  coord_flip() +
  labs(x = NULL, y = NULL)
```

There you have it. 2017 is #BAE. In fact, it's been used as an answer this year four whole times, and not once before (see below).

Plotting the appearance frequency of 2017's top 5 words by year: 

```{r echo = FALSE}
crossword %>%
  filter(word == "BAE" | word == "LGBT" | word == "IDRISELBA" | word == "ABBACY" | word == "ETSY" | word == "NSFW") %>%
  mutate(word = factor(word, levels = c("BAE", "LGBT", "IDRISELBA", "ABBACY", "ETSY", "NSFW"))) %>%
  count(year, word, sort = TRUE) %>%
  ggplot(aes(x = year, y = n, fill = word)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~word, ncol = 2) +
  labs(x = NULL, y = "Word Appearance Frequency")

```

Other observations:

- A manual look at the clues for IDRISELBA cited his roles in _The Wire_ (2002-2004) once and _Mandela: Long Walk to Freedom_ (2013) twice. Interestingly enough, no mention of the four films he's been in this year ( _Thor: Ragnarok_ , _The Mountain Between Us_, _The Dark Tower_ and _Molly's Game_ ).
- Mentions of LGBT and NSFW are steadily increasing. Read into that however you wish.

## Summary

- The most common words in the NYTimes crossword are short and vowel-heavy.
- Words have gotten longer since 1994, but most significantly so on Fridays and Saturdays.
- BAE, LGBT and IDRISELBA are the most 2017-specific words to appear,

## Further Steps

There were lots of ideas that I played around with that were either less compelling, difficult to execute or outside the scope of what I wanted to do here today. Here are some of them:

- What first names appear most often? Do male and female names appear with the same frequency?
- As above, but with cities and continental representation.
- What languages are represented the most? Many loanwords or straight-up foreign language words exist in the crossword but are very difficult to detect computationally out of the context of a sentence. 
- Who are the most prolific crossword submitters, and do they have distinct lexical differences between them?
- Any analysis involving the text of the crossword _clues_ and not just the answers.